{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements \n",
    "<ul>\n",
    "    <li>Your function should account for keyboard distance for all characters (even special characters)</li>\n",
    "    <li>Your function should account for levenshtein distance as well. If there are more typos, then the score should lean more towards 1 (since it is unlikely for a user to make so many typos)</li>\n",
    "    <li>Think about if it is more likely to make a horizontal typo vs a vertical typo, you may want to assign a weight to differentiate the typos</li>\n",
    "    <li>Think about the case when the strings have different lengths and how you should handle it</li>\n",
    "    <li>Think about if it is necessary to distinguish if the character is already very far away (e.g wikip9dia.org vs wikip0dia.org), both are most likely typosquats, is there a need for a different score? How many keyboard characters away then should I consider it to be not a typo vs not typo?</li>\n",
    "    <li>Try to think of any other conditions / requirements that I may have missed out, and feel free to suggest any</li>\n",
    "</ul>\n",
    "\n",
    "what about swapped letters, one-too-many letters\n",
    "\n",
    "numbers above qwertyuiop are possible typos, but some may be intended typosquats (i.e. o -> 0; E -> 3 ?)\n",
    "\n",
    "what about when a user presses 2 keys on accident? e.g. wikoipedia -> presses \"o\" and \"k\" when trying to press \"k\"\n",
    "\n",
    "are special chars/homoglyphs legal in the url box?\n",
    "\n",
    "what if they miss a letter?\n",
    "\n",
    "\n",
    "[python-Levenshtein PyPI](https://pypi.org/project/python-Levenshtein/)\n",
    "\n",
    "[euclidean distance using numpy (stack overflow)](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) (may help make calculating ED more efficient?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import dnstwist\n",
    "from tldextract import extract\n",
    "import Levenshtein as ls\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "keyboard_cartesian = {\n",
    "                        \"1\": {\"y\": -1, \"x\": 0},\n",
    "                        \"2\": {\"y\": -1, \"x\": 1},\n",
    "                        \"3\": {\"y\": -1, \"x\": 2},\n",
    "                        \"4\": {\"y\": -1, \"x\": 3},\n",
    "                        \"5\": {\"y\": -1, \"x\": 4},\n",
    "                        \"6\": {\"y\": -1, \"x\": 5},\n",
    "                        \"7\": {\"y\": -1, \"x\": 6},\n",
    "                        \"8\": {\"y\": -1, \"x\": 7},\n",
    "                        \"9\": {\"y\": -1, \"x\": 8},\n",
    "                        \"0\": {\"y\": -1, \"x\": 9},\n",
    "                        \"-\": {\"y\": -1, \"x\": 10},\n",
    "                        \"q\": {\"y\": 0, \"x\": 0},\n",
    "                        \"w\": {\"y\": 0, \"x\": 1},\n",
    "                        \"e\": {\"y\": 0, \"x\": 2},\n",
    "                        \"r\": {\"y\": 0, \"x\": 3},\n",
    "                        \"t\": {\"y\": 0, \"x\": 4},\n",
    "                        \"y\": {\"y\": 0, \"x\": 5},\n",
    "                        \"u\": {\"y\": 0, \"x\": 6},\n",
    "                        \"i\": {\"y\": 0, \"x\": 7},\n",
    "                        \"o\": {\"y\": 0, \"x\": 8},\n",
    "                        \"p\": {\"y\": 0, \"x\": 9},\n",
    "                        \"a\": {\"y\": 1, \"x\": 0},\n",
    "                        \"s\": {\"y\": 1, \"x\": 1},\n",
    "                        \"d\": {\"y\": 1, \"x\": 2},\n",
    "                        \"f\": {\"y\": 1, \"x\": 3},\n",
    "                        \"g\": {\"y\": 1, \"x\": 4},\n",
    "                        \"h\": {\"y\": 1, \"x\": 5},\n",
    "                        \"j\": {\"y\": 1, \"x\": 6},\n",
    "                        \"k\": {\"y\": 1, \"x\": 7},\n",
    "                        \"l\": {\"y\": 1, \"x\": 8},\n",
    "                        \"z\": {\"y\": 2, \"x\": 0},\n",
    "                        \"x\": {\"y\": 2, \"x\": 1},\n",
    "                        \"c\": {\"y\": 2, \"x\": 2},\n",
    "                        \"v\": {\"y\": 2, \"x\": 3},\n",
    "                        \"b\": {\"y\": 2, \"x\": 4},\n",
    "                        \"n\": {\"y\": 2, \"x\": 5},\n",
    "                        \"m\": {\"y\": 2, \"x\": 6}                    \n",
    "                     }\n",
    "\n",
    "def euclidean_distance(a,b):\n",
    "    X = (keyboard_cartesian[a]['x']-keyboard_cartesian[b]['x'])**2\n",
    "    Y = (keyboard_cartesian[a]['y']-keyboard_cartesian[b]['y'])**2\n",
    "    return sqrt(X+Y)\n",
    "\n",
    "print(euclidean_distance('q', 's'))\n",
    "print(euclidean_distance('s', 'e'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain_and_tld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return td + '.' + tsu\n",
    "\n",
    "def extract_tld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return tsu    \n",
    "\n",
    "def extract_sld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return td\n",
    "\n",
    "# whitelist = ['https://www.bankofsingapore.com/','http://www.ocbc.com','http://www.dbs.com','http://www.uobgroup.com','http://www.bnpparibas.com.sg','http://www.icbc.com.cn/new-branch/xjp/index.htm','https://www.citibank.com.sg/','https://www.maybank2u.com.sg/','http://www.sbising.com','https://www.sc.com/sg/','http://www.icicibank.com','https://www.hsbc.com.sg/','http://www.ccb.com/','https://www.bankofchina.com/sg/','https://www.boi.com.sg/','http://www.jpmorgan.com','http://iob.com','http://www.indian-bank.com','https://www.hlbank.com.sg','http://www.ca-cib.com','http://www.cimb.com/','http://www.bankofamerica.com/','http://www.bbl.co.th/','http://www.bgcpartners.com/','http://www.ebsgroup.si/','http://www.hlf.com.sg/','http://www.sif.com.sg/','http://www.singapurafinance.com.sg/','https://www.mas.gov.sg/']\n",
    "# print(len(whitelist))\n",
    "\n",
    "# print('Number of whitelisted domains input: ', len(whitelist))\n",
    "\n",
    "# whitelist_domains = []\n",
    "# whitelist_slds = []\n",
    "# for url in whitelist:\n",
    "#     whitelist_domains.append(extract_domain_and_tld(url))\n",
    "#     whitelist_slds.append(extract_sld(url))\n",
    "# typosquat = []\n",
    "# for url in whitelist_domains:\n",
    "#     fuzz = dnstwist.DomainFuzz(url)\n",
    "#     fuzz.generate()\n",
    "#     typosquat.extend([x['domain-name'] for x in fuzz.domains])\n",
    "    \n",
    "# print(typosquat[200:260])\n",
    "# #Lookups in sets are much more efficient\n",
    "# typosquat = set(typosquat)\n",
    "\n",
    "# #Delete the original whitelisted domains from the blacklist set\n",
    "# typosquat.difference_update(whitelist_domains)\n",
    "\n",
    "# print('Number of typosquatted urls generated: ', len(typosquat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bankofsingapore.com', 'ocbc.com', 'dbs.com', 'uobgroup.com', 'bnpparibas.com.sg', 'icbc.com.cn', 'citibank.com.sg', 'maybank2u.com.sg', 'sbising.com', 'sc.com']\n",
      "['bankofsingapore', 'ocbc', 'dbs', 'uobgroup', 'bnpparibas', 'icbc', 'citibank', 'maybank2u', 'sbising', 'sc']\n"
     ]
    }
   ],
   "source": [
    "print(whitelist_domains[:10])\n",
    "print(whitelist_slds[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "legit = \"wikipedia.org\"\n",
    "typo = \"wiiipedia.org\" \n",
    "typosqt = \"wikiped1a.org\"\n",
    "\n",
    "def typo_check(url):\n",
    "    for i in range(len(legit)):\n",
    "        if legit[i] != url[i]:\n",
    "            result = euclidean_distance(legit[i], url[i])\n",
    "            if result >= 1.5:\n",
    "                # typosquat\n",
    "                return 1\n",
    "            else:\n",
    "                # typo\n",
    "                return 0\n",
    "\n",
    "print(typo_check(typosqt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T : URL being tested <br>\n",
    "L : Legit URL <br>\n",
    "LD : levenshtein distance <br>\n",
    "ED : euclidean distance <br>\n",
    "\n",
    "Assuming: <br>\n",
    "-> given T, we know what L is. <br>\n",
    "-> no reason to press shift; urls are not case sensitive, and the only legal special character is hyphen, which does not require shift <br>\n",
    "-> if len(T) = len(L) + 1, assume that extra letters are at the end of domain names\n",
    "\n",
    "\n",
    "Then, checks:\n",
    "- if there are special characters in T, typosquat (in domain names: hyphens are allowed, underscores are not)\n",
    "- if length of T = length of L + 1, check how far away the extra letter is from the previous letter. was it fat-fingered?\n",
    "- if length of T = length of L, check LD. if > 2, definitely typosquat\n",
    "- if length of T = length of L AND LD <= 2, check ED. if any error has ED > 1.5, typosquat\n",
    "\n",
    "definitely typosquat:\n",
    "- special char present anywhere\n",
    "- len(T) > len(L) + 1\n",
    "- LD > 2\n",
    "- ED > 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of typosquatted urls generated:  13515\n"
     ]
    }
   ],
   "source": [
    "special_characters = ['~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '\"', '*', '|', ',', '&', '<', '`', '}', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/']\n",
    "\n",
    "whitelist = ['https://www.bankofsingapore.com/']\n",
    "\n",
    "whitelist_domains = []\n",
    "whitelist_slds = []\n",
    "for url in whitelist:\n",
    "    whitelist_domains.append(extract_domain_and_tld(url))\n",
    "    whitelist_slds.append(extract_sld(url))\n",
    "typosquat = []\n",
    "for url in whitelist_domains:\n",
    "    fuzz = dnstwist.DomainFuzz(url)\n",
    "    fuzz.generate()\n",
    "    typosquat.extend([x['domain-name'] for x in fuzz.domains])\n",
    "    \n",
    "#Lookups in sets are much more efficient\n",
    "typosquat = set(typosquat)\n",
    "\n",
    "#Delete the original whitelisted domains from the blacklist set\n",
    "typosquat.difference_update(whitelist_domains)\n",
    "\n",
    "print('Number of typosquatted urls generated: ', len(typosquat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typo\n"
     ]
    }
   ],
   "source": [
    "def is_typo(url):\n",
    "    l = whitelist_domains[0]\n",
    "    score = 0 # 0 typo, 1 typosquat\n",
    "    \n",
    "    # checks if illegal special characters are present\n",
    "    if any(char in url for char in special_characters):\n",
    "        return \"Typosquat, illegal special characters\"\n",
    "    \n",
    "    # compares lengths\n",
    "    if len(url) > len(l)+ 1 :\n",
    "        return \"Typosquat, too long\"\n",
    "    else:\n",
    "        # assuming no errors in tld\n",
    "        url_sld = extract_sld(url)\n",
    "        l_sld = extract_sld(l)\n",
    "        for i in range(len(l_sld)):\n",
    "            if l[i] != url[i]:\n",
    "                result = euclidean_distance(l[i], url[i])\n",
    "                if result >= 1.5:\n",
    "                    # typosquat\n",
    "                    return \"Typosquat, typo key(s) too far away.\"\n",
    "                else:\n",
    "                    # typo\n",
    "                    return \"Typo\"\n",
    "        url_last = url_sld[-1]\n",
    "        l_last = l_sld[-1]\n",
    "        result = euclidean_distance(l_last, url_last)\n",
    "        if result >= 1.5:\n",
    "            # typosquat\n",
    "            return \"Typosquat, extra character too far away.\"\n",
    "        else:\n",
    "            # typo\n",
    "            return \"Typo\"\n",
    "    \n",
    "    # checks LD\n",
    "    if ls.distance(url, l) > 2:\n",
    "        return \"Typosquat, more than 2 errors\"\n",
    "    else:\n",
    "        for i in range(len(l)):\n",
    "            if l[i] != url[i]:\n",
    "                result = euclidean_distance(l[i], url[i])\n",
    "                if result >= 1.5:\n",
    "                    # typosquat\n",
    "                    return \"Typosquat, typo key(s) too far away.\"\n",
    "                else:\n",
    "                    # typo\n",
    "                    return \"Typo\"\n",
    "\n",
    "typo = \"bankofsingsporea.com\"\n",
    "ts1 = \"bankofsing-pore.com\"\n",
    "    \n",
    "print(is_typo(typo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
