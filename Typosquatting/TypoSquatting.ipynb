{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements \n",
    "<ul>\n",
    "    <li>Your function should account for keyboard distance for all characters (even special characters)</li>\n",
    "    <li>Your function should account for levenshtein distance as well. If there are more typos, then the score should lean more towards 1 (since it is unlikely for a user to make so many typos)</li>\n",
    "    <li>Think about if it is more likely to make a horizontal typo vs a vertical typo, you may want to assign a weight to differentiate the typos</li>\n",
    "    <li>Think about the case when the strings have different lengths and how you should handle it</li>\n",
    "    <li>Think about if it is necessary to distinguish if the character is already very far away (e.g wikip9dia.org vs wikip0dia.org), both are most likely typosquats, is there a need for a different score? How many keyboard characters away then should I consider it to be not a typo vs not typo?</li>\n",
    "    <li>Try to think of any other conditions / requirements that I may have missed out, and feel free to suggest any</li>\n",
    "</ul>\n",
    "\n",
    "what about swapped letters, one-too-many letters\n",
    "\n",
    "numbers above qwertyuiop are possible typos, but some may be intended typosquats (i.e. o -> 0; E -> 3 ?)\n",
    "\n",
    "what about when a user presses 2 keys on accident? e.g. wikoipedia -> presses \"o\" and \"k\" when trying to press \"k\"\n",
    "\n",
    "are special chars/homoglyphs legal in the url box?\n",
    "\n",
    "what if they miss a letter?\n",
    "\n",
    "\n",
    "[python-Levenshtein PyPI](https://pypi.org/project/python-Levenshtein/)\n",
    "\n",
    "[euclidean distance using numpy (stack overflow)](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) (may help make calculating ED more efficient?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import dnstwist\n",
    "from tldextract import extract\n",
    "import Levenshtein as ls\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.8284271247461903\n"
     ]
    }
   ],
   "source": [
    "keyboard_cartesian = {\n",
    "                        \"1\": {\"y\": -1, \"x\": 0},\n",
    "                        \"2\": {\"y\": -1, \"x\": 1},\n",
    "                        \"3\": {\"y\": -1, \"x\": 2},\n",
    "                        \"4\": {\"y\": -1, \"x\": 3},\n",
    "                        \"5\": {\"y\": -1, \"x\": 4},\n",
    "                        \"6\": {\"y\": -1, \"x\": 5},\n",
    "                        \"7\": {\"y\": -1, \"x\": 6},\n",
    "                        \"8\": {\"y\": -1, \"x\": 7},\n",
    "                        \"9\": {\"y\": -1, \"x\": 8},\n",
    "                        \"0\": {\"y\": -1, \"x\": 9},\n",
    "                        \"-\": {\"y\": -1, \"x\": 10},\n",
    "                        \"q\": {\"y\": 0, \"x\": 0},\n",
    "                        \"w\": {\"y\": 0, \"x\": 1},\n",
    "                        \"e\": {\"y\": 0, \"x\": 2},\n",
    "                        \"r\": {\"y\": 0, \"x\": 3},\n",
    "                        \"t\": {\"y\": 0, \"x\": 4},\n",
    "                        \"y\": {\"y\": 0, \"x\": 5},\n",
    "                        \"u\": {\"y\": 0, \"x\": 6},\n",
    "                        \"i\": {\"y\": 0, \"x\": 7},\n",
    "                        \"o\": {\"y\": 0, \"x\": 8},\n",
    "                        \"p\": {\"y\": 0, \"x\": 9},\n",
    "                        \"a\": {\"y\": 1, \"x\": 0},\n",
    "                        \"s\": {\"y\": 1, \"x\": 1},\n",
    "                        \"d\": {\"y\": 1, \"x\": 2},\n",
    "                        \"f\": {\"y\": 1, \"x\": 3},\n",
    "                        \"g\": {\"y\": 1, \"x\": 4},\n",
    "                        \"h\": {\"y\": 1, \"x\": 5},\n",
    "                        \"j\": {\"y\": 1, \"x\": 6},\n",
    "                        \"k\": {\"y\": 1, \"x\": 7},\n",
    "                        \"l\": {\"y\": 1, \"x\": 8},\n",
    "                        \"z\": {\"y\": 2, \"x\": 0},\n",
    "                        \"x\": {\"y\": 2, \"x\": 1},\n",
    "                        \"c\": {\"y\": 2, \"x\": 2},\n",
    "                        \"v\": {\"y\": 2, \"x\": 3},\n",
    "                        \"b\": {\"y\": 2, \"x\": 4},\n",
    "                        \"n\": {\"y\": 2, \"x\": 5},\n",
    "                        \"m\": {\"y\": 2, \"x\": 6}                    \n",
    "                     }\n",
    "\n",
    "def euclidean_distance(a,b):\n",
    "    X = (keyboard_cartesian[a]['x']-keyboard_cartesian[b]['x'])**2\n",
    "    Y = (keyboard_cartesian[a]['y']-keyboard_cartesian[b]['y'])**2\n",
    "    return sqrt(X+Y)\n",
    "\n",
    "print(euclidean_distance('q', 'r'))\n",
    "print(euclidean_distance('q', 'c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions & Codes For Testing\n",
    "functions to extract TLD & SLD\n",
    "\n",
    "codes to generate various suspicious URLs to test based off of legit URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain_and_tld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return td + '.' + tsu\n",
    "\n",
    "def extract_tld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return tsu    \n",
    "\n",
    "def extract_sld(url):\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return td\n",
    "\n",
    "# whitelist = ['https://www.bankofsingapore.com/','http://www.ocbc.com','http://www.dbs.com','http://www.uobgroup.com','http://www.bnpparibas.com.sg','http://www.icbc.com.cn/new-branch/xjp/index.htm','https://www.citibank.com.sg/','https://www.maybank2u.com.sg/','http://www.sbising.com','https://www.sc.com/sg/','http://www.icicibank.com','https://www.hsbc.com.sg/','http://www.ccb.com/','https://www.bankofchina.com/sg/','https://www.boi.com.sg/','http://www.jpmorgan.com','http://iob.com','http://www.indian-bank.com','https://www.hlbank.com.sg','http://www.ca-cib.com','http://www.cimb.com/','http://www.bankofamerica.com/','http://www.bbl.co.th/','http://www.bgcpartners.com/','http://www.ebsgroup.si/','http://www.hlf.com.sg/','http://www.sif.com.sg/','http://www.singapurafinance.com.sg/','https://www.mas.gov.sg/']\n",
    "# print(len(whitelist))\n",
    "\n",
    "# print('Number of whitelisted domains input: ', len(whitelist))\n",
    "\n",
    "# whitelist_domains = []\n",
    "# whitelist_slds = []\n",
    "# for url in whitelist:\n",
    "#     whitelist_domains.append(extract_domain_and_tld(url))\n",
    "#     whitelist_slds.append(extract_sld(url))\n",
    "# typosquat = []\n",
    "# for url in whitelist_domains:\n",
    "#     fuzz = dnstwist.DomainFuzz(url)\n",
    "#     fuzz.generate()\n",
    "#     typosquat.extend([x['domain-name'] for x in fuzz.domains])\n",
    "    \n",
    "# print(typosquat[200:260])\n",
    "# #Lookups in sets are much more efficient\n",
    "# typosquat = set(typosquat)\n",
    "\n",
    "# #Delete the original whitelisted domains from the blacklist set\n",
    "# typosquat.difference_update(whitelist_domains)\n",
    "\n",
    "# print('Number of typosquatted urls generated: ', len(typosquat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bankofsingapore.com', 'ocbc.com', 'dbs.com', 'uobgroup.com', 'bnpparibas.com.sg', 'icbc.com.cn', 'citibank.com.sg', 'maybank2u.com.sg', 'sbising.com', 'sc.com']\n",
      "['bankofsingapore', 'ocbc', 'dbs', 'uobgroup', 'bnpparibas', 'icbc', 'citibank', 'maybank2u', 'sbising', 'sc']\n"
     ]
    }
   ],
   "source": [
    "print(whitelist_domains[:10])\n",
    "print(whitelist_slds[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Try\n",
    "simply checking against Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "legit = \"wikipedia.org\"\n",
    "typo = \"wiiipedia.org\" \n",
    "typosqt = \"wikiped1a.org\"\n",
    "\n",
    "def typo_check(url):\n",
    "    for i in range(len(legit)):\n",
    "        if legit[i] != url[i]:\n",
    "            result = euclidean_distance(legit[i], url[i])\n",
    "            if result >= 1.5:\n",
    "                # typosquat\n",
    "                return 1\n",
    "            else:\n",
    "                # typo\n",
    "                return 0\n",
    "\n",
    "print(typo_check(typosqt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T : URL being tested <br>\n",
    "L : Legit URL <br>\n",
    "LD : levenshtein distance <br>\n",
    "ED : euclidean distance <br>\n",
    "\n",
    "Assuming: <br>\n",
    "-> given T, we know what L is. <br>\n",
    "-> no reason to press shift; urls are not case sensitive, and the only legal special character is hyphen, which does not require shift <br>\n",
    "-> if len(T) = len(L) + 1, assume that extra letters are at the end of domain names\n",
    "\n",
    "\n",
    "Then, checks:\n",
    "- if there are special characters in T, typosquat (in domain names: hyphens are allowed, underscores are not)\n",
    "- if length of T = length of L + 1, check how far away the extra letter is from the previous letter. was it fat-fingered?\n",
    "- if length of T = length of L, check LD. if > 2, definitely typosquat\n",
    "- if length of T = length of L AND LD <= 2, check ED. if any error has ED > 1.5, typosquat\n",
    "\n",
    "definitely typosquat:\n",
    "- special char present anywhere\n",
    "- len(T) > len(L) + 1\n",
    "- LD > 2\n",
    "- ED > 1.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined codes to aid in testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of typosquatted urls generated:  13515\n"
     ]
    }
   ],
   "source": [
    "special_characters = ['~', ':', \"'\", '+', '[', '\\\\', '@', '^', '{', '%', '(', '\"', '*', '|', ',', '&', '<', '`', '}', '_', '=', ']', '!', '>', ';', '?', '#', '$', ')', '/']\n",
    "\n",
    "whitelist = ['https://www.bankofsingapore.com/']\n",
    "\n",
    "whitelist_domains = []\n",
    "whitelist_slds = []\n",
    "for url in whitelist:\n",
    "    whitelist_domains.append(extract_domain_and_tld(url))\n",
    "    whitelist_slds.append(extract_sld(url))\n",
    "typosquat = []\n",
    "for url in whitelist_domains:\n",
    "    fuzz = dnstwist.DomainFuzz(url)\n",
    "    fuzz.generate()\n",
    "    typosquat.extend([x['domain-name'] for x in fuzz.domains])\n",
    "    \n",
    "#Lookups in sets are much more efficient\n",
    "typosquat = set(typosquat)\n",
    "\n",
    "#Delete the original whitelisted domains from the blacklist set\n",
    "typosquat.difference_update(whitelist_domains)\n",
    "\n",
    "print('Number of typosquatted urls generated: ', len(typosquat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_typo(url) Function\n",
    "Code Flow:\n",
    "- checks if url has any special characters\n",
    "- checks LD of url against legit URL\n",
    "- checks length of url against lenght of legit URL\n",
    "- checks the ED of any wrong char in url against corresponding char in legit URL\n",
    "\n",
    "todo:\n",
    "- also check tld\n",
    "- add extra chars to any of the letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fankofsingapore.com\n",
      "bankofsimgap0re.com\n",
      "bankofsingapoer.com\n",
      "bwnkofsingapore.com\n",
      "bankofsignapore.com\n",
      "bankofslmgapore.com\n",
      "bankkfsingapore.com\n",
      "banklfsingapore.com\n",
      "banlofsingapore.com\n",
      "bankofskngapore.com\n",
      "bamk0fsingapore.com\n",
      "bamkofsingapore.com\n",
      "nankofsingapore.com\n",
      "bajkofsingapore.com\n",
      "bankobsingapore.com\n",
      "bznkofsingapore.com\n",
      "bankpfsingapore.com\n",
      "banoofsingapore.com\n",
      "bankofaingapore.com\n",
      "bank9fsingapore.com\n",
      "bankofsingapofe.com\n",
      "bankofsingapord.com\n",
      "bankofsingaporde.com\n",
      "bank0fsingapore.com\n",
      "bankofsingapored.com\n",
      "bankofsingapkre.com\n",
      "bankofsingaporre.com\n",
      "bankofsibgapore.com\n",
      "bankofsingaplre.com\n",
      "bankofsongapore.com\n",
      "bankofsingapo5e.com\n",
      "bankofqingapore.com\n",
      "bankofslngapore.com\n",
      "bankofzingapore.com\n",
      "bankofcingapore.com\n",
      "bank0fsimgapore.com\n",
      "bankofsingapores.com\n",
      "hankofsingapore.com\n",
      "bankofsingalore.com\n",
      "bankofxingapore.com\n",
      "bankocsingapore.com\n",
      "bankifsingapore.com\n",
      "bankofsimgapore.com\n",
      "bankofsingapo5re.com\n",
      "bankofsingapoee.com\n",
      "bankofsinbapore.com\n",
      "vankofsingapore.com\n",
      "bankofsingwpore.com\n",
      "bankofsingspore.com\n",
      "bank0fsingap0re.com\n",
      "bankofsinvapore.com\n",
      "bankofs9ngapore.com\n",
      "banmofsingapore.com\n",
      "baniofsingapore.com\n",
      "bankofsingapote.com\n",
      "bankofsintapore.com\n",
      "bamkofsimgapore.com\n",
      "bankofsingaporr.com\n",
      "bankofslngap0re.com\n",
      "bankofsingapors.com\n",
      "bankofsingaporfe.com\n",
      "bankofsingapor4.com\n",
      "bankofsingqpore.com\n",
      "bankofsingapire.com\n",
      "bankorsingapore.com\n",
      "bankofsinhapore.com\n",
      "gankofsingapore.com\n",
      "bankofsingaporer.com\n",
      "bamkofsingap0re.com\n",
      "bankodsingapore.com\n",
      "bankofsingap9re.com\n",
      "bankofsingapode.com\n",
      "bankofeingapore.com\n",
      "bankofsingappre.com\n",
      "bankofsingapodre.com\n",
      "bankofsingapotre.com\n",
      "bankofdingapore.com\n",
      "bankofsingaporew.com\n",
      "bankofsingaporee.com\n",
      "bankofsingaopre.com\n",
      "bankofsihgapore.com\n",
      "bankofsingapo4re.com\n",
      "bankofs8ngapore.com\n",
      "bankofsinga0ore.com\n",
      "bankofsjngapore.com\n",
      "bamkofslngapore.com\n",
      "bankofsingaporef.com\n",
      "bankogsingapore.com\n",
      "bankofsingap0re.com\n",
      "bankofsungapore.com\n",
      "bankovsingapore.com\n",
      "bank0fslngapore.com\n",
      "bankofsingaporw.com\n",
      "bankofsingaoore.com\n",
      "bankotsingapore.com\n",
      "bankofsingapor4e.com\n",
      "bsnkofsingapore.com\n",
      "bankofsingapor3.com\n",
      "bankofsijgapore.com\n",
      "bankofsingapofre.com\n",
      "banjofsingapore.com\n",
      "bahkofsingapore.com\n",
      "bqnkofsingapore.com\n",
      "bankofwingapore.com\n",
      "bankofsinfapore.com\n",
      "bankofsingapo4e.com\n",
      "babkofsingapore.com\n",
      "banokfsingapore.com\n",
      "bankofsingzpore.com\n",
      "bankofsinyapore.com\n",
      "bankofsingapoere.com\n"
     ]
    }
   ],
   "source": [
    "def is_typo(url):\n",
    "    l = whitelist_domains[0]\n",
    "    \n",
    "    url_sld = extract_sld(url)\n",
    "    l_sld = extract_sld(l)\n",
    "    \n",
    "    url_len = len(url_sld)\n",
    "    l_len = len(l_sld)\n",
    "    \n",
    "    # checks if illegal special characters are present\n",
    "    if any(char in url_sld for char in special_characters) or url_sld.startswith(\"-\") or url_sld.endswith(\"-\"):\n",
    "        return 1\n",
    "    \n",
    "    # checks LD\n",
    "    if ls.distance(url_sld, l_sld) > 2:\n",
    "        return 1\n",
    "     \n",
    "    # compares lengths\n",
    "    if url_len > l_len + 1:\n",
    "        return 1\n",
    "    elif url_len < l_len:\n",
    "        # TODO: add more checks here\n",
    "        return 1\n",
    "    else:\n",
    "        # assuming no errors in tld\n",
    "        for i in range(l_len):\n",
    "            if l_sld[i] != url_sld[i]:\n",
    "                result = euclidean_distance(l_sld[i], url_sld[i])\n",
    "                if result >= 1.5:\n",
    "                    return 1\n",
    "        if url_len == l_len + 1:\n",
    "            url_last = url_sld[-1]\n",
    "            l_last = l_sld[-1]\n",
    "            result = euclidean_distance(l_last, url_last)\n",
    "            if result >= 1.5:\n",
    "                return 1    \n",
    "    return 0\n",
    "\n",
    "for url in typosquat:\n",
    "    # if typo\n",
    "    if is_typo(url) == 0:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "<u>Potential Results</u>: <br>\n",
    "0: Typo <br>\n",
    "1: Typosquat\n",
    "\n",
    "<u>Test Cases</u>:\n",
    "1. Legit URL (Expected Result: 0)\n",
    "2. Substitute 1 char with SC (Expected Result: 1)\n",
    "3. Substitute 1 char with hyphen (Expected Result: 1)\n",
    "4. Substitute 1 char with wrong char, within ED boundary (Expected Result: 0)\n",
    "5. Substitute 2 char with wrong char, within ED boundary (Expected Result: 0)\n",
    "6. Substitute 3 char with wrong char, within ED boundary(Expected Result: 1)\n",
    "7. Append 1 char, within ED boundary of last char (Expected Result: 0)\n",
    "8. Append 1 char, exceeding ED boundary (Expected Result: 1)\n",
    "9. Append 2 char, within ED boundary(Expected Result: 1)\n",
    "10. Remove 1 char (Expected Result: 1)\n",
    "    \n",
    "<u>Conclusion/Notes</u>:\n",
    "- need to check entire URL (SLD + TLD) because of potential periods in domain name, which can be removed when extracting SLD\n",
    "- include more checks for suspicious URLs that are shorter than original URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL 0 : 0\n",
      "URL 1 : 1\n",
      "URL 2 : 1\n",
      "URL 3 : 0\n",
      "URL 4 : 0\n",
      "URL 5 : 1\n",
      "URL 6 : 0\n",
      "URL 7 : 1\n",
      "URL 8 : 1\n",
      "URL 9 : 1\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\"bankofsingapore.com\", \n",
    "              \"bankofs!ngapore.com\", \n",
    "              \"bankofsing-pore.com\", \n",
    "              \"bankofsingaporr.com\", \n",
    "              \"bankofsingapoer.com\", \n",
    "              \"bankofsingapier.com\", \n",
    "              \"bankofsingaporee.com\", \n",
    "              \"bankofsingaporep.com\", \n",
    "              \"bankofsingaporeee.com\", \n",
    "              \"bankofsingapor.com\"]\n",
    "\n",
    "for i in range(len(test_cases)):\n",
    "    print(\"URL\", i, \":\", is_typo(test_cases[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
