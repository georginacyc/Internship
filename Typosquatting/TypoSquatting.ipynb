{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements \n",
    "<ul>\n",
    "    <li>Your function should account for keyboard distance for all characters (even special characters)</li>\n",
    "    <li>Your function should account for levenshtein distance as well. If there are more typos, then the score should lean more towards 1 (since it is unlikely for a user to make so many typos)</li>\n",
    "    <li>Think about if it is more likely to make a horizontal typo vs a vertical typo, you may want to assign a weight to differentiate the typos</li>\n",
    "    <li>Think about the case when the strings have different lengths and how you should handle it</li>\n",
    "    <li>Think about if it is necessary to distinguish if the character is already very far away (e.g wikip9dia.org vs wikip0dia.org), both are most likely typosquats, is there a need for a different score? How many keyboard characters away then should I consider it to be not a typo vs not typo?</li>\n",
    "    <li>Try to think of any other conditions / requirements that I may have missed out, and feel free to suggest any</li>\n",
    "</ul>\n",
    "\n",
    "what about swapped letters, one-too-many letters\n",
    "\n",
    "numbers above qwertyuiop are possible typos, but some may be intended typosquats (i.e. o -> 0; E -> 3 ?)\n",
    "\n",
    "what about when a user presses 2 keys on accident? e.g. wikoipedia -> presses \"o\" and \"k\" when trying to press \"k\"\n",
    "\n",
    "are special chars/homoglyphs legal in the url box?\n",
    "\n",
    "what if they miss a letter?\n",
    "\n",
    "\n",
    "[python-Levenshtein PyPI](https://pypi.org/project/python-Levenshtein/)\n",
    "\n",
    "[euclidean distance using numpy (stack overflow)](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) (may help make calculating ED more efficient?)\n",
    "\n",
    "[top 10 most common TLDs](https://www.statista.com/statistics/265677/number-of-internet-top-level-domains-worldwide/)\n",
    "\n",
    "[domain name regex](https://medium.com/@vaghasiyaharryk/how-to-validate-a-domain-name-using-regular-expression-9ab484a1b430)\n",
    "\n",
    "\n",
    "[Prototype 3 string check](https://stackoverflow.com/questions/774316/python-difflib-highlighting-differences-inline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import dnstwist\n",
    "from tldextract import extract\n",
    "import pylev as ls\n",
    "# import Levenshtein as ls\n",
    "import numpy as np\n",
    "import difflib as dl\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyboard Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "keyboard_cartesian = {\n",
    "                        \"1\": {\"y\": -1, \"x\": 0},\n",
    "                        \"2\": {\"y\": -1, \"x\": 1},\n",
    "                        \"3\": {\"y\": -1, \"x\": 2},\n",
    "                        \"4\": {\"y\": -1, \"x\": 3},\n",
    "                        \"5\": {\"y\": -1, \"x\": 4},\n",
    "                        \"6\": {\"y\": -1, \"x\": 5},\n",
    "                        \"7\": {\"y\": -1, \"x\": 6},\n",
    "                        \"8\": {\"y\": -1, \"x\": 7},\n",
    "                        \"9\": {\"y\": -1, \"x\": 8},\n",
    "                        \"0\": {\"y\": -1, \"x\": 9},\n",
    "                        \"-\": {\"y\": -1, \"x\": 10},\n",
    "                        \"q\": {\"y\": 0, \"x\": 0},\n",
    "                        \"w\": {\"y\": 0, \"x\": 1},\n",
    "                        \"e\": {\"y\": 0, \"x\": 2},\n",
    "                        \"r\": {\"y\": 0, \"x\": 3},\n",
    "                        \"t\": {\"y\": 0, \"x\": 4},\n",
    "                        \"y\": {\"y\": 0, \"x\": 5},\n",
    "                        \"u\": {\"y\": 0, \"x\": 6},\n",
    "                        \"i\": {\"y\": 0, \"x\": 7},\n",
    "                        \"o\": {\"y\": 0, \"x\": 8},\n",
    "                        \"p\": {\"y\": 0, \"x\": 9},\n",
    "                        \"a\": {\"y\": 1, \"x\": 0},\n",
    "                        \"s\": {\"y\": 1, \"x\": 1},\n",
    "                        \"d\": {\"y\": 1, \"x\": 2},\n",
    "                        \"f\": {\"y\": 1, \"x\": 3},\n",
    "                        \"g\": {\"y\": 1, \"x\": 4},\n",
    "                        \"h\": {\"y\": 1, \"x\": 5},\n",
    "                        \"j\": {\"y\": 1, \"x\": 6},\n",
    "                        \"k\": {\"y\": 1, \"x\": 7},\n",
    "                        \"l\": {\"y\": 1, \"x\": 8},\n",
    "                        \";\": {\"y\": 2, \"x\": 9},\n",
    "                        \"'\": {\"y\": 2, \"x\": 10},\n",
    "                        \"z\": {\"y\": 2, \"x\": 0},\n",
    "                        \"x\": {\"y\": 2, \"x\": 1},\n",
    "                        \"c\": {\"y\": 2, \"x\": 2},\n",
    "                        \"v\": {\"y\": 2, \"x\": 3},\n",
    "                        \"b\": {\"y\": 2, \"x\": 4},\n",
    "                        \"n\": {\"y\": 2, \"x\": 5},\n",
    "                        \"m\": {\"y\": 2, \"x\": 6},\n",
    "                        \",\": {\"y\": 2, \"x\": 7},\n",
    "                        \".\": {\"y\": 2, \"x\": 8},\n",
    "                        \"/\": {\"y\": 2, \"x\": 9}                   \n",
    "                     }\n",
    "\n",
    "def euclidean_distance(a,b):\n",
    "    X = (keyboard_cartesian[a]['x']-keyboard_cartesian[b]['x'])**2\n",
    "    Y = (keyboard_cartesian[a]['y']-keyboard_cartesian[b]['y'])**2\n",
    "    return sqrt(X+Y)\n",
    "\n",
    "print(euclidean_distance('q', 'w'))\n",
    "print(euclidean_distance('q', 's'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of typosquatted urls generated:  7900\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/44113335/extract-domain-from-url-in-python\n",
    "\n",
    "def replace_special_char(char):\n",
    "    flag = '\"!@#$%^&*()+?_=,<>'':\\\\'\n",
    "    flag_list = [char for char in flag]\n",
    "    if char.isalnum()==False and char in flag:\n",
    "        return 'Z'\n",
    "    return char\n",
    "    \n",
    "# Clean the string first. The extract python library cannot properly extract the domain from URLs with special characters\n",
    "\n",
    "# 1. make string lower case\n",
    "# 2. replace all flagged special characters with 'Z'\n",
    "# 3. extract the domain or TLD\n",
    "# 4. replace all 'Z' with '!'\n",
    "# 5. calculate edit distance\n",
    "\n",
    "def clean_string(url):\n",
    "    # First make the string lowercase\n",
    "    url = url.lower()\n",
    "\n",
    "    # ':' is a flagged character, but if it appears with http or https it is fine\n",
    "    url = url.replace('https://','')\n",
    "    url = url.replace('http://','')\n",
    "    return ''.join([replace_special_char(char) for char in url])\n",
    "    \n",
    "def extract_domain_and_tld(url):\n",
    "    url = clean_string(url)\n",
    "    tsd, td, tsu = extract(url)\n",
    "    final = td + '.' + tsu\n",
    "    return final.replace('Z','!')\n",
    "    \n",
    "def extract_tld(url):\n",
    "    url = clean_string(url)\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return tsu.replace('Z','!')  \n",
    "\n",
    "def extract_sld(url):\n",
    "    url = clean_string(url)\n",
    "    tsd, td, tsu = extract(url)\n",
    "    return td.replace('Z','!')\n",
    "\n",
    "# Theres no need for this container to be mutable and tuples are faster\n",
    "# Index 0 - 9 = most popular to least popular\n",
    "tlds = (\"com\", \"ru\", \"org\", \"net\", \"in\", \"ir\", \"au\", \"uk\", \"de\", \"br\")\n",
    "\n",
    "whitelist = ['https://www.wikipedia.org/']\n",
    "\n",
    "\n",
    "whitelist_domains = []\n",
    "whitelist_slds = []\n",
    "for url in whitelist:\n",
    "    whitelist_domains.append(extract_domain_and_tld(url))\n",
    "    whitelist_slds.append(extract_sld(url))\n",
    "typosquat = []\n",
    "for url in whitelist_domains:\n",
    "    fuzz = dnstwist.DomainFuzz(url)\n",
    "    fuzz.generate()\n",
    "    typosquat.extend([x['domain-name'] for x in fuzz.domains])\n",
    "    \n",
    "#Lookups in sets are much more efficient\n",
    "typosquat = set(typosquat)\n",
    "\n",
    "#Delete the original whitelisted domains from the blacklist set\n",
    "typosquat.difference_update(whitelist_domains)\n",
    "\n",
    "print('Number of typosquatted urls generated: ', len(typosquat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype 4\n",
    "- included LD == 1 for further checks\n",
    "- added new helper function: exceeds_ked_check()\n",
    "- improved efficiency, removed redundant/repetitive codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input - 1 URL\n",
    "# Output - True / False\n",
    "\n",
    "# e.g contains_special_characters(wikipedia.org) \n",
    "# expected output False\n",
    "\n",
    "# e.g contains_special_characters(wikipedi@.org) \n",
    "# expected output True\n",
    "\n",
    "def contains_special_characters(url):\n",
    "    return not re.match(\"^((?!-)[A-Za-z0-9-]{1,}(?<!-)\\.)+[A-Za-z0-9]{1,}$\", url)\n",
    "\n",
    "\n",
    "# Helper function to find out if the first TLD is more common than the second TLD\n",
    "\n",
    "# Input - 2 TLDs\n",
    "# Output - True / False\n",
    "\n",
    "# e.g exact_tld_swap(com, org) \n",
    "# expected output True\n",
    "\n",
    "# e.g exact_tld_swap(org, com) \n",
    "# expected output False\n",
    "\n",
    "def tld_more_common(tld1, tld2):    \n",
    "    tld1_index = 10\n",
    "    tld2_index = 10\n",
    "    if tld1 in tlds:\n",
    "        tld1_index = tlds.index(tld1)\n",
    "    if tld2 in tlds:\n",
    "        tld2_index = tlds.index(tld2)\n",
    "    if tld2_index > tld1_index:\n",
    "        return True\n",
    "    elif tld2_index < tld1_index:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Helper function to check if \"wrong\" character is within KED of any of the other supplied characters\n",
    "\n",
    "# Input - 4 characters\n",
    "# Output - False\n",
    "\n",
    "# e.g. exceeds_ked_check(\"i\", \"i\", \"k\", \"i\")\n",
    "# expected output True\n",
    "\n",
    "# e.g. exceeds_ked_check(\"p\", \"d\", \"e\", \"m\")\n",
    "# expected output False\n",
    "    \n",
    "def exceeds_ked_check(left, right, correct, wrong):\n",
    "    result = True\n",
    "    \n",
    "    # if the wrong/extra char is at the start of the url, the left will most likely be empty\n",
    "    if left != \"\":\n",
    "        if euclidean_distance(left, wrong) < 1.5:\n",
    "            result = False\n",
    "    \n",
    "    # if the wrong/extra char is at the end of the url, the right will most likely be empty\n",
    "    if right != \"\":\n",
    "        if euclidean_distance(right, wrong) < 1.5:\n",
    "            result = False\n",
    "    \n",
    "    # if the error is an extra char, there wont be a \"correct\" char\n",
    "    if correct != \"\":\n",
    "        if euclidean_distance(correct, wrong) < 1.5:\n",
    "            result = False\n",
    "        \n",
    "    return result\n",
    "    \n",
    "    \n",
    "# Helper function to perform various euclidean distance checks based off of the lengths of both URLs\n",
    "\n",
    "# Input - 2 URLs\n",
    "# Output - dictionary of results\n",
    "\n",
    "# e.g. edit_check(\"w1k1pedia.org\", \"wikipedia.org\")\n",
    "# expected output: {'result': 1, 'reasons_typosquat': [\"'1' key and 'i' key are too far apart\", \"'1' key and 'i' key are too far apart\"], 'reasons_typo': []}\n",
    "\n",
    "def edit_check(sus_url, legit_url):\n",
    "    result = {\"result\": 0, \"reasons_typosquat\": [], \"reasons_typo\": []}\n",
    "    \n",
    "    # retrieving length of both URLs\n",
    "    sus_len = len(sus_url)\n",
    "    legit_len = len(legit_url)\n",
    "    \n",
    "    # retrieving levenshtein distance of both urls\n",
    "    ld = ls.levenshtein(sus_url, legit_url)\n",
    "    \n",
    "    # if the suspicious is only missing characters, then it's highly likely a typo than a typosquat\n",
    "    if sus_len == legit_len - 1 and ld == 1 or sus_len == legit_len - 2 and ld == 2:\n",
    "        result[\"reasons_typo\"].append(\"Only missing 1-2 characters\")\n",
    "    \n",
    "    else:\n",
    "        # creating an object that compares both urls\n",
    "        seqm = dl.SequenceMatcher(None, sus_url, legit_url)\n",
    "\n",
    "        # get_opcodes() gets the \"differences\" between each url, or the steps required for first url to match second url\n",
    "        for opcode, a0, a1, b0, b1 in seqm.get_opcodes():\n",
    "            # a : first url\n",
    "            # b : second url\n",
    "            # a0, a1 | b0, b1 : index range holding the characters being compared\n",
    "            # opcode : \"equal\", \"insert\", \"delete\", \"replace\" -- indicates the action require to turn a to b\n",
    "\n",
    "            # if a character has to be deleted, means it's an extra character\n",
    "            if opcode == 'delete':\n",
    "                \n",
    "                # extra character(s)\n",
    "                extra_char = seqm.a[a0:a1]\n",
    "                \n",
    "                # if extra characters are side by side\n",
    "                if len(extra_char) == 2:\n",
    "                    \n",
    "                    # extract each extra char\n",
    "                    extra1 = extra_char[0]\n",
    "                    extra2 = extra_char[1]\n",
    "\n",
    "                    left_char = seqm.a[a0-1:a1-2]\n",
    "                    right_char = seqm.a[a0+2:a1+1]\n",
    "\n",
    "                    if exceeds_ked_check(left_char, right_char, \"\", extra1) and exceeds_ked_check(extra1, \"\", \"\", extra2):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Extra character(s) ('{}') exceed keyboard euclidean distance boundary\".format(extra1))\n",
    "                        return result\n",
    "                    elif exceeds_ked_check(left_char, right_char, \"\", extra2):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Extra character(s) ('{}') exceed keyboard euclidean distance boundary\".format(extra2))\n",
    "                        return result\n",
    "                    \n",
    "                # if the extra character is on its own\n",
    "                else:\n",
    "                    left_char = seqm.a[a0-1:a1-1]\n",
    "                    right_char = seqm.a[a0+1:a1+1]\n",
    "                    \n",
    "                    if exceeds_ked_check(left_char, right_char, \"\", extra_char):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Extra character ('{}') exceeds keyboard euclidean distance boundary\".format(extra_char))\n",
    "                        return result\n",
    "                \n",
    "            # if a character has to be replaced, means its a swapped character\n",
    "            elif opcode == 'replace':\n",
    "                wrong_char = seqm.a[a0:a1]\n",
    "                correct_char = seqm.b[b0:b1]\n",
    "                \n",
    "                # if there are 2 wrong characters side by side\n",
    "                # therefore, wrong_char == 2, correct char == 2\n",
    "                if len(wrong_char) == 2 and len(correct_char) == 2:\n",
    "                    \n",
    "                    # extract each wrong char, and each correct char for comparison\n",
    "                    wrong1 = wrong_char[0]\n",
    "                    wrong2 = wrong_char[1]\n",
    "                    correct1 = correct_char[0]\n",
    "                    correct2 = correct_char[1]\n",
    "                    left_char = seqm.a[a0-1:a1-2]\n",
    "                    right_char = seqm.a[a0+2:a1+1]\n",
    "                    \n",
    "                    if exceeds_ked_check(left_char, correct2, correct1, wrong1) and exceeds_ked_check(wrong1, \"\", \"\", wrong2):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong1))\n",
    "                        return result\n",
    "                    elif exceeds_ked_check(correct1, right_char, correct2, wrong2):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong2))\n",
    "                        return result\n",
    "                \n",
    "                # if there is an extra char + a wrong char side-by-side, both will be replaced by the 1 correct char\n",
    "                # therefore, wrong_char == 2, correct_char == 1\n",
    "                elif len(wrong_char) == 2:\n",
    "                    \n",
    "                    # extract each wrong char for comparison\n",
    "                    wrong1 = wrong_char[0]\n",
    "                    wrong2 = wrong_char[1]\n",
    "                    left_char = seqm.a[a0-1:a1-2]\n",
    "                    right_char = seqm.a[a0+2:a1+1]\n",
    "                    \n",
    "                    if exceeds_ked_check(left_char, wrong2, correct_char, wrong1):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Extra/Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong1))\n",
    "                        return result\n",
    "                    elif exceeds_ked_check(wrong1, right_char, correct_char, wrong2):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Extra/Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong2))\n",
    "                        return result\n",
    "                \n",
    "                # if there is a wrong char + a missing char side-by-side, the wrong char will be replace by the correct char + the missing char\n",
    "                # therefore, wrong_char == 1, correct char == 2\n",
    "                elif len(correct_char) == 2:\n",
    "                    \n",
    "                    # extract each correct char for comparison\n",
    "                    correct1 = correct_char[0]\n",
    "                    correct2 = correct_char[1]\n",
    "                    \n",
    "                    if exceeds_ked_check(\"\", \"\", correct1, wrong_char) and exceeds_ked_check(\"\", \"\", correct2, wrong_char):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong_char))\n",
    "                        return result\n",
    "                \n",
    "                # if there is only one wrong char, to be replaced by one correct char\n",
    "                # therefore, wrong_char == 1, correct char == 1\n",
    "                else:\n",
    "                    if exceeds_ked_check(\"\", \"\", correct_char, wrong_char):\n",
    "                        result[\"result\"] = 1\n",
    "                        result[\"reasons_typosquat\"].append(\"Wrong character ('{}') exceeds keyboard euclidean distance boundary\".format(wrong_char))\n",
    "                        return result\n",
    "                    \n",
    "        result[\"reasons_typo\"].append(\"Extra/Wrong characters within keyboard euclidean distance boundary\")\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_typo(sus_url, legit_url):\n",
    "    # preparing \n",
    "    result = {\"suspicious url\": sus_url, \"original url\": legit_url, \"result\": 0, \"reasons_typosquat\": [], \"reasons_typo\": []}\n",
    "    \n",
    "    # extracting SLD from both URLs\n",
    "    sus_sld = extract_sld(sus_url)\n",
    "    legit_sld = extract_sld(legit_url)\n",
    "    \n",
    "    # extracting TLD from both URLs\n",
    "    sus_tld = extract_tld(sus_url)\n",
    "    legit_tld = extract_tld(legit_url)\n",
    "    \n",
    "    # retrieving length of both URLs\n",
    "    sus_len = len(sus_url)\n",
    "    legit_len = len(legit_url)\n",
    "    \n",
    "    # check for illegal special characters\n",
    "    if contains_special_characters(sus_url):\n",
    "        result[\"result\"] = 1\n",
    "        result[\"reasons_typosquat\"].append(\"Illegal characters found in url\")\n",
    "        return result\n",
    "    \n",
    "    # check for exact TLD swap\n",
    "    if sus_sld == legit_sld and sus_tld != legit_tld:\n",
    "        if tld_more_common(sus_tld, legit_tld):\n",
    "            result[\"reasons_typo\"].append(\"TLD is more common\")\n",
    "            return result\n",
    "        else:\n",
    "            result[\"result\"] = 1\n",
    "            result[\"reasons_typosquat\"].append(\"TLD is less common\")\n",
    "            return result\n",
    "    \n",
    "    # check edit distance\n",
    "    ld = ls.levenshtein(sus_url, legit_url)\n",
    "    \n",
    "    # if only 1 or 2 edits\n",
    "    if ld == 1 or ld == 2:\n",
    "        res = edit_check(sus_url, legit_url)\n",
    "        \n",
    "        result[\"reasons_typosquat\"].extend(res[\"reasons_typosquat\"])\n",
    "        result[\"reasons_typo\"].extend(res[\"reasons_typo\"])\n",
    "        \n",
    "        if res[\"result\"] == 1:\n",
    "            result[\"result\"] = 1\n",
    "            return result\n",
    "    \n",
    "    # if 3 or more edits\n",
    "    else:\n",
    "        result[\"result\"] = \"Inconclusive\"\n",
    "        return result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suspicious url</th>\n",
       "      <th>original url</th>\n",
       "      <th>result</th>\n",
       "      <th>reasons_typosquat</th>\n",
       "      <th>reasons_typo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedi@.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[Illegal characters found in url]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikipedia.com</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[TLD is more common]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikipedia.br</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[TLD is less common]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikipedi.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Only missing 1-2 characters]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kipedia.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Only missing 1-2 characters]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wikipediabb.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[Extra character(s) ('b') exceed keyboard euclidean distance boundary]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wwikipediac.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[Extra character ('c') exceeds keyboard euclidean distance boundary]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wikipedia.bvg</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Extra/Wrong characters within keyboard euclidean distance boundary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wikipemnia.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Extra/Wrong characters within keyboard euclidean distance boundary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wbipedia.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[Wrong character ('b') exceeds keyboard euclidean distance boundary]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>wiklped1o.0rg</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wikiped1a.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>1</td>\n",
       "      <td>[Wrong character ('1') exceeds keyboard euclidean distance boundary]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wikipediaa.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Extra/Wrong characters within keyboard euclidean distance boundary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wlklpedla.org</td>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>Inconclusive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     suspicious url   original url        result  \\\n",
       "0     wikipedi@.org  wikipedia.org             1   \n",
       "1     wikipedia.com  wikipedia.org             0   \n",
       "2      wikipedia.br  wikipedia.org             1   \n",
       "3      wikipedi.org  wikipedia.org             0   \n",
       "4       kipedia.org  wikipedia.org             0   \n",
       "5   wikipediabb.org  wikipedia.org             1   \n",
       "6   wwikipediac.org  wikipedia.org             1   \n",
       "7     wikipedia.bvg  wikipedia.org             0   \n",
       "8    wikipemnia.org  wikipedia.org             0   \n",
       "9      wbipedia.org  wikipedia.org             1   \n",
       "10    wiklped1o.0rg  wikipedia.org  Inconclusive   \n",
       "11    wikiped1a.org  wikipedia.org             1   \n",
       "12   wikipediaa.org  wikipedia.org             0   \n",
       "13    wlklpedla.org  wikipedia.org  Inconclusive   \n",
       "\n",
       "                                                         reasons_typosquat  \\\n",
       "0                                        [Illegal characters found in url]   \n",
       "1                                                                       []   \n",
       "2                                                     [TLD is less common]   \n",
       "3                                                                       []   \n",
       "4                                                                       []   \n",
       "5   [Extra character(s) ('b') exceed keyboard euclidean distance boundary]   \n",
       "6     [Extra character ('c') exceeds keyboard euclidean distance boundary]   \n",
       "7                                                                       []   \n",
       "8                                                                       []   \n",
       "9     [Wrong character ('b') exceeds keyboard euclidean distance boundary]   \n",
       "10                                                                      []   \n",
       "11    [Wrong character ('1') exceeds keyboard euclidean distance boundary]   \n",
       "12                                                                      []   \n",
       "13                                                                      []   \n",
       "\n",
       "                                                            reasons_typo  \n",
       "0                                                                     []  \n",
       "1                                                   [TLD is more common]  \n",
       "2                                                                     []  \n",
       "3                                          [Only missing 1-2 characters]  \n",
       "4                                          [Only missing 1-2 characters]  \n",
       "5                                                                     []  \n",
       "6                                                                     []  \n",
       "7   [Extra/Wrong characters within keyboard euclidean distance boundary]  \n",
       "8   [Extra/Wrong characters within keyboard euclidean distance boundary]  \n",
       "9                                                                     []  \n",
       "10                                                                    []  \n",
       "11                                                                    []  \n",
       "12  [Extra/Wrong characters within keyboard euclidean distance boundary]  \n",
       "13                                                                    []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit_url = whitelist_domains[0]\n",
    "test_urls = [\"wikipedi@.org\", \"wikipedia.com\", \"wikipedia.br\", \"wikipedi.org\", \"kipedia.org\", \"wikipediabb.org\", \"wwikipediac.org\", \"wikipedia.bvg\", \"wikipemnia.org\", \"wbipedia.org\", \"wiklped1o.0rg\", \"wikiped1a.org\", \"wikipediaa.org\", \"wlklpedla.org\"] \n",
    "test_results = []\n",
    "\n",
    "for url in test_urls:\n",
    "    test_results.append(is_typo(url, legit_url))\n",
    "    \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame(test_results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
