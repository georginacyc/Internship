{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics Course: Machine Problem 1\n",
    "## Contents:\n",
    "* [Introduction](#intro)\n",
    "* [Problem Scenario](#scene)\n",
    "* [Part 1: Data Ingestion](#ingest)\n",
    "* [Part 2: Data Processing](#process)\n",
    "* [Part 3: Data Enrichment](#enrich)\n",
    "* [Part 4: Data Visualization](#plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "Welcome to the first machine problem of the data analytics course! \n",
    "\n",
    "This machine problem is designed to introduce you to some of the fundamental tasks faced by data analysts on a day-to-day basis.\n",
    "On a higher level, these tasks include:\n",
    "1. Data ingestion\n",
    "2. Data processing, transformation and enrichment\n",
    "3. Data visualization\n",
    "\n",
    "Of course, this machine problem assumes that you have the pre-requisites of python under your belt, meaning you understand:\n",
    "- python data types\n",
    "- python [data structures](https://docs.python.org/3.5/tutorial/datastructures.html) (such as list, dict and tuple)\n",
    "- python [control flows](https://docs.python.org/3.5/tutorial/controlflow.html) (if-else and for-loops)\n",
    "- how to declare, build and call [python functions](https://docs.python.org/3.5/tutorial/modules.html)\n",
    "- how to find help in [python documentation](https://docs.python.org/3/index.html) and [stackoverflow](https://stackoverflow.com/)\n",
    "\n",
    "If the above python concepts sounds alien to you, please read up on them in the python documentation. There is no shortcut around a solid foundation in programming in data analytics.\n",
    "\n",
    "We know that this machine problem subsequent homeworks will be a challenging, but the struggle is part of the learning process. When stuck, please proactively ask questions on [Piazza](https://piazza.com/), do a google search, or refer to some of the code already written as examples on how things are done. Happy learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario <a class=\"anchor\" id=\"scene\"></a>\n",
    "\n",
    "In any **ideal** scenario, we always start a data analytics project or task with a **specific problem** in mind to solve. Otherwise this will happen:\n",
    "\n",
    "<img src=\"./images/thor_nail.jpg\" alt=\"drawing\" width=\"400px\"/>\n",
    "\n",
    "---\n",
    "But alas, the world is not ideal. After a lengthy meeting with the team operating the Snort Intrusion Detection System, who claimed they are \"seeing a lot of alerts\" everyday, there is a requirement to \"do something useful\" to make sense of the snort logs that are generated. The reality is some data science problems start like this, but in cases like these, we can start with some data exploration to formulate what may be useful to end-users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:Data Ingestion <a class=\"anchor\" id=\"ingest\"></a>\n",
    "\n",
    "Regardless of the problem, the first step of any data problem is to ingest the data into any platform or tools that you are going use to analyse the data. As you can see from above, the logs are in **unstructured** format, meaning they come as free text. These data were originally collected more for humans to read than for machines to analyse. For data to be **machine readable** we will have to parse the data into some form of **structured** format in order to compute on them.\n",
    "\n",
    "**Sample snort logs in raw form**\n",
    "<img src=\"./images/sample_snort.png\"/>\n",
    "\n",
    "There are many forms of **data structures** to impose on the data. In the programming world, this usually means organizing the data into one of the following:\n",
    "- array, also know as list in python.\n",
    "- hashtable, also know as dict in python.\n",
    "- and many others such as trees, graphs, linked-list etc.\n",
    "\n",
    "In the relational database world, structured data usually means storing the data into columns and assigning a data type to each column.\n",
    "\n",
    "For this part of the assignment, your task is write the code to parse the snort logs into a structured format:\n",
    "```\n",
    "Dict(\n",
    "    'timestamp': string, \n",
    "    'msg': string, \n",
    "    'classification': string, \n",
    "    'priority': string, \n",
    "    'protocol': string,\n",
    "    'src_ip': string,\n",
    "    'dst_ip': string\n",
    ")\n",
    "```\n",
    "\n",
    "Notice all the datatypes are strings? This is not the final correct structure but we will worry about the datatype later.\n",
    "\n",
    "Next, you must read the snort logs from the file and call your parse() function to apply it to each line.\n",
    "\n",
    "Ultimately, we want to convert the data into a Pandas DataFrame called ```snort_df```\n",
    "\n",
    "**Hint:** The places to write code are marked with python's docstring\n",
    "```python\n",
    "\"\"\"\n",
    "Problem n:\n",
    "Some additional instructions to help you.\n",
    "\"\"\"\n",
    "# Write your code here\n",
    "```\n",
    "\n",
    "**Hint:** Python's [regular expression package](https://docs.python.org/3/library/re.html) will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Problem 1a:\n",
    "    The parse function takes in each line of snort logs and parse it into a dictionary.\n",
    "    :param: line (str) - a line of snort logs\n",
    "    :return: (Dict) - a python dict containing the following keys:\n",
    "            'timestamp': string, 'msg': string, 'classification': string, 'priority': string, 'protocol': string,'src_ip': string,\n",
    "            'dst_ip': string\n",
    "    \"\"\"\n",
    "    # Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 1b:\n",
    "Write the code to open snort logs in \"alert.fast\" and send each line into the parse function declared above.\n",
    "Put the return into a python list called parsed_data.\n",
    "\"\"\"\n",
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the first line of your parsed data for sanity check\n",
    "print(parsed_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "<img src=\"./images/out1.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 1c:\n",
    "Convert your parsed_data into a Pandas DataFrame called snort_df.\n",
    "\"\"\"\n",
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 5 lines of your dataframe for sanity check.\n",
    "snort_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "<img src=\"./images/out2.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Processing with Pandas <a class=\"anchor\" id=\"process\"></a>\n",
    "As described in its own documentation:\n",
    "[**Pandas**](https://pandas.pydata.org/pandas-docs/stable/index.html) is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python.\n",
    "\n",
    "As left off in Problem 1, the data is now represented in a Pandas DataFrame.\n",
    "\n",
    "However, we still can't really work with this data because the data types of every column are strings! We should at least convert timestamp to a datetime datatype. You will also notice that the IP and ports are still together. We will need to separate them out.\n",
    "\n",
    "In Problem 2, you will need to:\n",
    "1. Separate port from ```src_ip``` and ```dst_ip``` columns\n",
    "1. Convert timestamp column into ```DateTimeIndex``` datatype\n",
    "2. Make timestamp into the index of Pandas Dataframe\n",
    "3. Drop timestamp column which has become redundant after making it the index.\n",
    "\n",
    "### Hint: Lambda functions and the apply method\n",
    "In Pandas DataFrame, there is a neat built in function called apply(). We can pass it a function to run that function on every row in the DataFrame. For example:\n",
    "```python\n",
    "def my_function(row):\n",
    "    # do something to row and return a value\n",
    "\n",
    "my_df['col'].apply(my_function)\n",
    "```\n",
    "The way to select a column named 'col' in pandas is as follows:\n",
    "```python\n",
    "my_df['col']\n",
    "```\n",
    "Lambda functions in python are useful for creating small one-line functions. Together with apply, we can do the following:\n",
    "```python\n",
    "# This example splits the strings in 'col' column by ',' separator.\n",
    "my_df['col'].apply(lambda x: x.split(','))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting the ports out\n",
    "def get_port(ip_port):\n",
    "    tmp = ip_port.split(\":\")\n",
    "    if len(tmp) == 2:\n",
    "        port = tmp[1]\n",
    "    else:\n",
    "        port = ''\n",
    "    return port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 2a:\n",
    "Understand the get_port() function above and apply it to the snort_df dataframe to create 2 new columns: src_port and dst_port.\n",
    "Then, use lambda functions to fill src_ip and dst_ip columns with just the IPs.\n",
    "\"\"\"\n",
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview your data here, it should look like the expected output.\n",
    "snort_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "<img src=\"./images/out3.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# The data does not come with a date but since I know this data was collected in 2012, we cheat a little.\n",
    "snort_df['timestamp'] = snort_df['timestamp'].apply(lambda x: '2012/' + x)\n",
    "# The faster way to do the above is this:\n",
    "#snort_df['timestamp'] = '2012/' + snort_df['timestamp']\n",
    "# but this is a topic for another time.\n",
    "\n",
    "\"\"\"\n",
    "Problem 2b:\n",
    "Convert the timestamp column into datetime datatype, then assign it as the index. Lastly drop the timestamp column\n",
    "and rearrange the columns in the order ['msg', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'classification', 'protocol', 'priority']\n",
    "\"\"\"\n",
    "# Write your code here\n",
    "\n",
    "# Rearrange the columns and display\n",
    "snort_df = snort_df[['msg', 'src_ip', 'src_port', 'dst_ip', 'dst_port', 'classification', 'protocol', 'priority']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data.\n",
    "snort_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "<img src=\"./images/out4.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Enriching Data <a class=\"anchor\" id=\"enrich\"></a>\n",
    "\n",
    "Sometimes, it is important to provide some additional information to your data by melding information from other sources. We shall use the GeoLite2 database to provide the country context for our src_ip and dst_ip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip2country(ip, db_reader):\n",
    "    \"\"\"\n",
    "    Problem 3:\n",
    "    Write the ip2country function that takes in as input an ip and a database reader\n",
    "    and return the country. If ip is not found in database, return \"Internal\" for 192.168.x.x and \"Not Found\" for others.\n",
    "    \"\"\"\n",
    "    # Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoip2.database\n",
    "\n",
    "reader = geoip2.database.Reader('data/GeoLite2-City_20180501/GeoLite2-City.mmdb')\n",
    "snort_df['src_country'] = snort_df['src_ip'].apply(lambda x: ip2country(x, reader))\n",
    "snort_df['dst_country'] = snort_df['dst_ip'].apply(lambda x: ip2country(x, reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snort_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "<img src=\"./images/out5.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a dataset that is well pre-processed and enriched with everything you need. At this point, it is good practice to store it into a datalake for easy query and usage by other data scientists in future. Since we do not have a datalake, we shall store it into a local database called sqlite to simulate a datalake.\n",
    "\n",
    "Normally, you will have to write sql statements to save to database. With Pandas, it becomes easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('data/datalake.db')\n",
    "snort_df.to_sql('snort', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is like a checkpoint. If you need to load data and do not wish to repeat the pre-processing steps, you can start from \n",
    "# this cell.\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('data/datalake.db')\n",
    "query = \"SELECT * from snort\"\n",
    "snort_df = pd.read_sql(query, conn, index_col='timestamp', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your data well transformed and neatly stored in a \"datalake\", the rest of the data scientists will love you as their analysis is now more convenient. No more parsing raw logs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Plot Some Data <a class=\"anchor\" id=\"plotting\"></a>\n",
    "Phew! Data processing took up the bulk of the work as always. Now we can finally start giving the boss \"something useful\".\n",
    "\n",
    "For a start, we may want to provide some situation awareness on what are some of the traffic that are originating from or ending in Singapore IP addresses. For this problem, filter the snort_df by country and aggregate the count by each hour. Then, plot this data on a graph using [matplotlib](https://matplotlib.org/) and [plotly](https://plot.ly/python/).\n",
    "\n",
    "### Hint :\n",
    "Plotting in plotly generally follows four steps:\n",
    "1. Define the plot data\n",
    "2. Define a layout\n",
    "3. Create a plotly figure\n",
    "4. Plot the plotly figure\n",
    "\n",
    "Check out some examples to find out how others write this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 4a:\n",
    "Filter the snort_df, keeping only entries with src_country = United States and dst_country = United States.\n",
    "Store the filtered data into a new variable us_df\n",
    "\"\"\"\n",
    "# Write your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output of first 5 rows of** ```us_df```:\n",
    "<img src=\"./images/out7.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataframe_static(input_df, title):\n",
    "    \"\"\"\n",
    "    Problem 4b:\n",
    "    Write the function to plot a bar graph of an aggregated count of the snort alerts each hour using matplotlib.\n",
    "    First aggregate the input df by the hour, then create a plotly bar chart with timestamp as the x-axis and count as the y-axis\n",
    "    :param: input_df - Input DataFrame to aggregate and plot.\n",
    "    :param: title - Give a title to the graph\n",
    "    \n",
    "    This is a difficult one. Ask the instructor for help if needed.\n",
    "    \"\"\"\n",
    "    # Write your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function here\n",
    "plot_dataframe_static(us_df, \"Attacks on United States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output of** ```plot_dataframe_static()```:\n",
    "<img src=\"./images/out8.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataframe(input_df, title):\n",
    "    \"\"\"\n",
    "    Problem 4c:\n",
    "    Write the function to plot a bar graph of an aggregated count of the snort alerts each hour using plotly.\n",
    "    First aggregate the input df by the hour, then create a plotly bar chart with timestamp as the x-axis and count as the y-axis\n",
    "    :param: input_df - Input DataFrame to aggregate and plot.\n",
    "    :param: title - Give a title to the graph\n",
    "    :return: plotly figure data\n",
    "    \n",
    "    This is a difficult one. Ask the instructor for help if needed.\n",
    "    \"\"\"\n",
    "    # Write your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function here\n",
    "fig = plot_dataframe(us_df, \"Attacks on United States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output of** ```plot_dataframe()```:\n",
    "<img src=\"./images/out6.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still not very useful to be frank. All the graph tells us is that we are seeing huge amount of malicious traffic originating from all outgoing to servers that are likely to be in United States in Nov 2012. Perhaps we can do some additional filtering to drill down on the granularity of the data?\n",
    "\n",
    "## Static or Interactive Plots?\n",
    "Matplotlib is a good library to provide static plots when compiling a data science report, but as you might have noticed, each plot is not very informative in standalone. That is why when we use matplotlib, we always add a discussion or description in words (much like what this paragraph does).\n",
    "\n",
    "If you need plots to be self-sustaining with information due to whatever reason (e.g in a dashboard where it is not possible to provide a written discussion of plots that may differ from day-to-day), it is better to build interactive plots. This is where libraries such as plotly comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given an IP, map it's attack pattern\n",
    "\n",
    "Let's do something cool by building a \"data driven\" widget! We want to see what kind of attacks are hitting our internal servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\"\"\"\n",
    "Problem 4c:\n",
    "Find the right place to call your plot_dataframe() function with the right parameters to complete the code below.\n",
    "\"\"\"\n",
    "# Complete your code below.\n",
    "\n",
    "# IPython Widgets for Interactive UI\n",
    "dir_select = widgets.Dropdown(\n",
    "    options = [\"Incoming\", \"Outgoing\"],\n",
    "    description = 'Direction:',\n",
    "    value = \"Incoming\"\n",
    ")\n",
    "\n",
    "ip_select = widgets.Dropdown(\n",
    "    options = snort_df[snort_df['src_country'] == 'Internal']['src_ip'].unique(),\n",
    "    description = 'Threat:'\n",
    ")\n",
    "\n",
    "# Helper functions for interactivity\n",
    "def filter_by_direction(direction):\n",
    "    if direction == 'Incoming':\n",
    "        sub_df = snort_df[snort_df['dst_country'] == 'Internal']\n",
    "        ip_select.options = sub_df['dst_ip'].unique()\n",
    "    else:\n",
    "        sub_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "        ip_select.options = sub_df['src_ip'].unique()\n",
    "\n",
    "\n",
    "def filter_by_ip(ip):\n",
    "    if dir_select.value == \"Incoming\":\n",
    "        sub_df = snort_df[snort_df['dst_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['dst_ip'] == ip]\n",
    "    else:\n",
    "        sub_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['src_ip'] == ip]\n",
    "        \n",
    "    title = \"Attack Patterns on {}\".format(ip)\n",
    "\n",
    "    \n",
    "dir_widget = widgets.interactive(filter_by_direction, direction=dir_select)\n",
    "ip_widget = widgets.interactive(filter_by_ip, ip=ip_select)\n",
    "\n",
    "display(dir_widget)\n",
    "display(ip_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Problem 4d:\n",
    "Find the right place to call your plot_dataframe() function with the right parameters to complete the code below.\n",
    "\"\"\"\n",
    "# Complete your code below.\n",
    "\n",
    "# IPython Widgets for Interactive UI\n",
    "dir_select = widgets.Dropdown(\n",
    "    options = [\"Incoming\", \"Outgoing\"],\n",
    "    description = 'Direction:',\n",
    "    value = \"Incoming\"\n",
    ")\n",
    "\n",
    "internal_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "ip_list = internal_df['src_ip'].unique()\n",
    "ip_init = ip_list[0]\n",
    "ip_select = widgets.Dropdown(\n",
    "    options = ip_list,\n",
    "    description = 'IP:',\n",
    "    value = ip_init\n",
    ")\n",
    "\n",
    "alert_select = widgets.Dropdown(\n",
    "    options = internal_df[internal_df['src_ip'] == ip_init]['msg'].unique(),\n",
    "    description = 'Threat:'\n",
    ")\n",
    "\n",
    "def filter_by_direction(direction):\n",
    "    if direction == 'Incoming':\n",
    "        sub_df = snort_df[snort_df['dst_country'] == 'Internal']\n",
    "        ip_select.options = sub_df['dst_ip'].unique()\n",
    "        ip_select.value = ip_select.options[0]\n",
    "        alert_select.options = sub_df[sub_df['dst_ip'] == ip_select.value]['msg'].unique()\n",
    "    else:\n",
    "        sub_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "        ip_select.options = sub_df['src_ip'].unique()\n",
    "        ip_select.value = ip_select.options[0]\n",
    "        alert_select.options = sub_df[sub_df['src_ip'] == ip_select.value]['msg'].unique()\n",
    "\n",
    "\n",
    "def filter_by_ip(ip):\n",
    "    if dir_select.value == \"Incoming\":\n",
    "        sub_df = snort_df[snort_df['dst_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['dst_ip'] == ip]\n",
    "    else:\n",
    "        sub_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['src_ip'] == ip]\n",
    "        \n",
    "    ip_select.value = ip\n",
    "    # Update options for alert_select dropdown\n",
    "    alert_select.options = alert_df['msg'].unique()\n",
    "    \n",
    "def filter_by_msg(msg):\n",
    "    if dir_select.value == \"Incoming\":\n",
    "        sub_df = snort_df[snort_df['dst_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['dst_ip'] == ip_select.value]\n",
    "    else:\n",
    "        sub_df = snort_df[snort_df['src_country'] == 'Internal']\n",
    "        alert_df = sub_df[sub_df['src_ip'] == ip_select.value]\n",
    "        \n",
    "    df = alert_df[alert_df['msg'] == msg]\n",
    "    title = \"Attack Patterns of {} on {}\".format(msg, ip_select.value)\n",
    "\n",
    "    \n",
    "dir_widget = widgets.interactive(filter_by_direction, direction=dir_select)\n",
    "ip_widget = widgets.interactive(filter_by_ip, ip=ip_select)\n",
    "msg_widget = widgets.interactive(filter_by_msg, msg=alert_select)\n",
    "\n",
    "display(dir_widget)\n",
    "display(ip_widget)\n",
    "display(msg_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have built your first data driven application that provides insights into SNORT IDS logs. While it's level of \"usefulness\" is subjective and depends on the opinion of people, you can pat yourself on the back for developing something that helps user answer the following question:\n",
    "\n",
    "1. For a particular asset in my network, what are the threats as identified by the IDS?\n",
    "2. Is a particular threat persistently happening over a period of time? Or is it just a one time event?\n",
    "\n",
    "Take baby steps...\n",
    "\n",
    "## Takeaways\n",
    "\n",
    "1. Before the fun begins, the bulk of the work lies in data ingestion and data preprocessing.\n",
    "2. Always try to store all ingested data with a schema and/or data structure. Centralized data storage in a data lake is ideal for convenient future data analytics work.\n",
    "3. Data visualization is one of the (but not the only) tools of data analytics. Use it well.\n",
    "4. IPython Notebook is a powerful application. You can use it for data storytelling or even build interactive applications with plotly and ipython widgets.\n",
    "5. Pandas is the de-facto tool for data analysis on structured data. For unstructured data, it is more open ended.\n",
    "5. A lot of insights can be gained without machine learning. Sometimes the information is already in the data. Just filter, transform and aggregate!\n",
    "\n",
    "With point 5 said, you now have to basics to dive into more complex data analytics with machine learning next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
